{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# <center>Machine Learning</center>\n",
    "# <center>HW1</center>\n",
    "<center>Fan Yang</center>\n",
    "<center>UNI: fy2232</center>\n",
    "<center>02/10/2018</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "L(\\theta)&=\\prod_{i=1}^np(x_i|\\theta)\\\\\n",
    "&=\\prod_{i=1}^nx_i^2e^{-x/\\theta}\\\\\n",
    "&=e^{-\\sum x_i/\\theta}\\prod_{i=1}^nx_i^2\\\\\n",
    "\\text{the log likelihood is }~l(\\theta)&=\\log L(\\theta)\\\\\n",
    "&=-\\sum x_i/\\theta+2\\sum_{i=1}^n \\log x_i\\\\\n",
    "&=-\\frac{\\sum x_i}{\\theta}+2\\sum_{i=1}^n \\log x_i\\\\\n",
    "\\text{let } l(\\theta)=0,\\text{ then we get }~\\theta&= \\frac{2\\sum \\log x_i}{\\sum x_i}\\\\\n",
    "\\text{Therefore, }\\hat{\\theta}_{MLE}&= \\frac{2\\sum \\log x_i}{\\sum x_i}\\\\\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "L(\\theta)&=\\prod_{i=1}^np(x_i|\\theta)\\\\\n",
    "&=\\prod_{i=1}^nI_{\\{-\\theta\\leq x_i \\leq \\theta\\}}\\\\\n",
    "&=I_{\\{x_{(1)}\\geq -\\theta\\text{ and }x_{(n)}\\leq\\theta\\}}\\\\\n",
    "&=I_{\\{\\theta\\geq\\max(-x_{(1)},x_{(n)})\\}}\\\\\n",
    "\\end{split}\n",
    "where $x_{(1)}=\\min\\limits_i x_i$ and $x_{(n)}=\\max\\limits_i x_i$<br>\n",
    "When $\\theta\\geq\\max(-x_{(1)},x_{(n)}), L(\\theta)$ has the largest value 1.<br>\n",
    "Therefore, $\\theta_{MLE}=\\{\\theta\\geq0~|~\\theta\\geq\\max(-x_{(1)},x_{(n)})\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (iii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "L(\\mu,\\sigma)&=\\prod_{i=1}^np(x_i|\\mu,\\sigma)\\\\\n",
    "&=(\\frac{1}{\\sqrt{2\\pi}\\sigma})^n\\prod_{i=1}^n\\exp\\left({-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}\\right)\\\\\n",
    "&=(\\frac{1}{\\sqrt{2\\pi}\\sigma})^n\\exp\\left({-\\frac{\\sum(x_i-\\mu)^2}{2\\sigma^2}}\\right)\\\\\n",
    "\\text{the log likelihood is }~l(\\mu,\\sigma)&=\\log L(\\mu,\\sigma)\\\\\n",
    "&=-n\\log \\sqrt{2\\pi}\\sigma-\\frac{\\sum(x_i-\\mu)^2}{2\\sigma^2}\\\\\n",
    "\\end{split}\n",
    "In the case where the mean is unknown, the log-likelihood is maximized with respect to the parameter $\\{\\mu,\\sigma\\}$. The maximum likelihood estimator is\n",
    "\\begin{split}\n",
    "\\hat{\\mu}&=\\bar{X}_n=\\frac{1}{n}\\sum_{i=1}^nx_i\\\\\n",
    "\\hat{\\sigma}^2_{MLE}&=\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{X}_n)^2\\\\\n",
    "\\end{split}\n",
    "Now we show $\\hat{\\sigma}^2_{MLE}$ is not an unbiased estimator:\n",
    "\\begin{split}\n",
    "E(\\hat{\\sigma}^2_{MLE})&=E(\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{X}_n)^2\\\\\n",
    "&=\\frac{1}{n}E(\\sum_{i=1}^nx_i-\\bar{X}_n)^2\\\\\n",
    "&=\\frac{1}{n}\\times(n-1)\\sigma^2\\\\\n",
    "&=\\frac{n-1}{n}\\sigma^2\\\\\n",
    "\\end{split}\n",
    "which is not an unbiased estomator. Suppose we take $\\hat{\\sigma}^2=\\frac{n}{n-1}\\hat{\\sigma}^2_{MLE}$, then $E(\\hat{\\sigma}^2)=\\frac{n}{n-1}E(\\hat{\\sigma}^2_{MLE})=\\frac{n}{n-1}\\times\\frac{n-1}{n}\\sigma^2=\\sigma^2$ is unbiased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have likelihood function $L(\\theta|\\vec{x})$ and log likelihood $\\log L(\\theta|\\vec{x})$. And they can also written as $L(g(\\theta))$ and $\\log L(g(\\theta))$ Then we take derivative to get MLE:\n",
    "<br><br>\n",
    "$$\n",
    "\\frac{d \\log L(g(\\theta))}{d g(\\theta)}=\\frac{L'(g(\\theta))}{L(g(\\theta))} \\tag{1}\n",
    "$$<br>\n",
    "Let equation $(1)$ become 0 then we get MLE for $g(\\theta)$.<br>\n",
    "<br>\n",
    "$$\n",
    "\\frac{d \\log L(g(\\theta))}{d \\theta}=\\frac{d \\log L(g(\\theta))}{d g(\\theta)}\\frac{d g(\\theta))}{d \\theta}=\\frac{L'(g(\\theta))g'(\\theta)}{L(g(\\theta))} \\tag{2}\n",
    "$$\n",
    "<br>\n",
    "Let equation $(2)$ become 0 then we get MLE for $\\theta$, which is $\\theta_{ML}$.<br><br>\n",
    "Notice that when equation $(1)$ equals to 0, we can have equation $(2)$ equals to 0. Therefore, the MLE of $g(\\theta)$ is $g(\\theta_{ML}).$<br><br>\n",
    "From this result we can infer the MLE in Part(iii):\n",
    "\\begin{split}\n",
    "g(\\sigma^2)&=\\sqrt{\\sigma^2}=\\sigma\\\\\n",
    "\\sigma^2_{ML}&=\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{X}_n)^2\\\\\n",
    "\\sigma_{ML}=g(\\sigma^2_{ML})&=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{X}_n)^2}\\\\\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for any $g$,\n",
    "\\begin{split}\n",
    "Q(g)-Q(f)&=E_{x,y}[(g(x)-y)^2]-E_{x,y}[(f(x)-y)^2]\\\\\n",
    "&=\\int\\int (g(x)-y)^2p_{x,y}(x,y)dxdy - \\int\\int (f(x)-y)^2p_{x,y}(x,y)~dxdy\\\\\n",
    "&=\\int\\int [(g(x)-y)^2-(f(x)-y)^2]p_{x,y}(x,y)~dxdy\\\\\n",
    "&=\\int\\int [g(x)-f(x)][g(x)+f(x)-2y]p_{x,y}(x,y)~dxdy\\\\\n",
    "&=\\int\\int [g(x)-f(x)][g(x)+f(x)-2y]p_x(x)p(y|x)~dydx\\\\\n",
    "&=\\int\\int [g(x)-f(x)][g(x)+f(x)]p_x(x)p(y|x)~dydx\\\\\n",
    "&~ ~ ~ ~ ~-2\\int\\int y[g(x)-f(x)]p_x(x)p(y|x)~dydx\\\\\n",
    "&=\\int_x[g(x)-f(x)][g(x)+f(x)]p_x(x)\\int_y p(y|x)~dy~dx\\\\\n",
    "&~ ~ ~ ~ ~-2\\int_x[g(x)-f(x)]p_x(x)\\int_y yp(y|x)~dy~dx\\\\\n",
    "&=\\int_x[g(x)-f(x)][g(x)+f(x)]p_x(x)~dx\\\\\n",
    "&~ ~ ~ ~ ~-2\\int_x[g(x)-f(x)]p_x(x)E(Y|X=x)~dx\\\\\n",
    "&=\\int_x[g(x)-f(x)][g(x)+f(x)]p_x(x)~dx-2\\int_x[g(x)-f(x)]p_x(x)f(x)~dx\\\\\n",
    "&=\\int_x[g(x)-f(x)][g(x)-f(x)]p_x(x)~dx\\\\\n",
    "&=\\int_x(g(x)-f(x))^2p_x(x)~dx\\\\\n",
    "&\\geq0\\\\\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Symmetric : $M^T=(A^TA)^T=A^TA=M$<br><br>\n",
    "Positive semi-definite: $||M||=||A^TA||=||A^T||\\cdot||A||=||A||\\cdot||A||=||A||^2\\geq0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "\\beta^{(N)}&=\\eta\\nu+(I-\\nu M)\\beta^{(N-1)}\\\\\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
