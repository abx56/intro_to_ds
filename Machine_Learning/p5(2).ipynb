{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import random\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used to compute dictionary as vector\n",
    "def dic_linear(dic1,dic2,operator):\n",
    "    '''\n",
    "        dic1,dic2 - two dictionary to do plus or minus\n",
    "        operator  - -1: minus\n",
    "                    1: plus\n",
    "        Return the result dictionary.\n",
    "    '''\n",
    "    dic={k:dic1[k] for k in dic1}\n",
    "    for word in dic2:\n",
    "        if word not in dic:\n",
    "            dic[word]=0\n",
    "        if operator==1:\n",
    "            dic[word]+=dic2[word]\n",
    "        if operator==-1:\n",
    "            dic[word]-=dic2[word]\n",
    "    return dic\n",
    "\n",
    "def dic_dot(dic1,dic2):\n",
    "    '''\n",
    "        dic1,dic2 - two dictionary to do dot\n",
    "        Return the result.\n",
    "    '''\n",
    "    dot=0\n",
    "    for word in dic2:\n",
    "        if word in dic1:\n",
    "            dot+=dic1[word]*dic2[word]\n",
    "    return dot\n",
    "\n",
    "def dic_multi(diction,number):\n",
    "    '''\n",
    "        diction - the dictionary need to be multipled\n",
    "        number  - multiplier\n",
    "        Return a multipled dictionary.\n",
    "    '''\n",
    "    dic={k:diction[k]*number for k in diction}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used to do data representation\n",
    "def tf(text,n=1):\n",
    "    '''\n",
    "        text - the review need to be transformed\n",
    "        n    - n_gram: \n",
    "                        1 - unigram\n",
    "                        2 - bigram\n",
    "        Return a dictionary contains the tf of each word(s).\n",
    "    '''\n",
    "    words=text.split(' ')\n",
    "    word_dic={}\n",
    "    for i in range(len(words)-n+1):\n",
    "        #Form the n_gram\n",
    "        n_gram=''\n",
    "        for j in range(n):\n",
    "            n_gram=n_gram+words[i+j]\n",
    "        if n_gram not in word_dic:\n",
    "            word_dic[n_gram]=0\n",
    "        word_dic[n_gram]+=1\n",
    "    return word_dic\n",
    "\n",
    "def idf(reviews):\n",
    "    '''\n",
    "        reviews - a collection of documents\n",
    "        Return a dictionary contains the idf of each word.\n",
    "    '''\n",
    "    word_all={}\n",
    "    D=len(reviews)\n",
    "    #Form a dictionary contains all words appearing in D.\n",
    "    for review in reviews:\n",
    "        words=review.split(' ')\n",
    "        for word in words:\n",
    "            if word not in word_all:\n",
    "                word_all[word]=0\n",
    "    for review in reviews:\n",
    "        for word in word_all:\n",
    "            if word in review:\n",
    "                word_all[word]+=1\n",
    "    for word in word_all:\n",
    "        word_all[word]=numpy.log10(D/word_all[word])\n",
    "    return word_all\n",
    "    \n",
    "def tf_idf(text,word_all):\n",
    "    '''\n",
    "        text     - the review need to be transformed\n",
    "        word_all - a dictionary contains the idf of each word\n",
    "        Return a dictionary contains the tf_idf of each word.\n",
    "    '''\n",
    "    word_dic=tf(text)\n",
    "    DEL=[]\n",
    "    for word in word_dic:\n",
    "        #Deal with the situation if word doesn't appear in any document in D.\n",
    "        if word not in word_all:\n",
    "            DEL.append(word)\n",
    "        else:\n",
    "            word_dic[word]=word_dic[word]*word_all[word]\n",
    "    for word in DEL:\n",
    "        del word_dic[word]\n",
    "    return word_dic\n",
    "\n",
    "def representation(text,word_all={},pre='unigram'):\n",
    "    '''\n",
    "        text     - text need to be transformed\n",
    "        word_all - a dictionary contains the idf of each word;\n",
    "                   this is required when pre is 'tf-idf'\n",
    "        pre      - 'unigram'\n",
    "                   'bigram'\n",
    "                   'tf-idf'\n",
    "        Return the transformed vector.\n",
    "    '''\n",
    "    if pre=='unigram':\n",
    "        vec=tf(text)\n",
    "    if pre=='bigram':\n",
    "        vec=tf(text,n=2)\n",
    "    if pre=='tf-idf':\n",
    "        vec=tf_idf(text,word_all)\n",
    "    vec['GG']=1                      #lifting the data\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions used to get the classifier\n",
    "def preprocessing(data):\n",
    "    '''\n",
    "        Used to transform label 0 to -1.\n",
    "    '''\n",
    "    for i in range(len(data['text'])):\n",
    "        if data['label'][i]==0:\n",
    "            data['label'][i]=-1\n",
    "\n",
    "def Online_Perceptron(training,word_all={},pre='unigram'):\n",
    "    '''\n",
    "        training - the training set\n",
    "        word_all - if method is tf-idf, word_all is required\n",
    "        pre      - the method to do presentation:\n",
    "                        'unigram'\n",
    "                        'tf-idf'\n",
    "                        'bigram'\n",
    "        Return the weight.\n",
    "    '''\n",
    "    tr=copy.deepcopy(training)\n",
    "    #Transform label 0 to -1\n",
    "    preprocessing(tr)\n",
    "    #First pass\n",
    "    index=[i for i in range(len(tr['text']))]\n",
    "    random.shuffle(index)\n",
    "    w={}\n",
    "    for i in index:\n",
    "        vec=representation(tr['text'][i],word_all,pre)\n",
    "        dot=dic_dot(w,vec)\n",
    "        if tr['label'][i]*dot<=0:\n",
    "            w=dic_linear(w,vec,tr['label'][i])\n",
    "    #Second pass\n",
    "    random.shuffle(index)\n",
    "    W={}\n",
    "    n=1\n",
    "    for i in index:\n",
    "        vec=representation(tr['text'][i],word_all,pre)\n",
    "        dot=dic_dot(w,vec)\n",
    "        if tr['label'][i]*dot<=0:\n",
    "            if n==1:\n",
    "                W=dic_linear(W,w,1)\n",
    "            else:\n",
    "                inter=dic_multi(w,n)\n",
    "                W=dic_linear(W,inter,1)\n",
    "            w=dic_linear(w,vec,tr['label'][i])\n",
    "            n=1\n",
    "        else:\n",
    "            n+=1\n",
    "    inter=dic_multi(w,n)\n",
    "    W=dic_linear(W,inter,1)\n",
    "    W=dic_multi(W,1/(len(tr['text'])+1))\n",
    "    return W\n",
    "\n",
    "def posi_nega(w):\n",
    "    '''\n",
    "        Used to found the 10 most positive and negative words.\n",
    "    '''\n",
    "    lis=[(k,w[k]) for k in w]\n",
    "    lis=sorted(lis,key=lambda l:l[1])\n",
    "    positive=lis[-10:]\n",
    "    negative=lis[:10]\n",
    "    return {'posi':positive,'nega':negative}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testit(train,test,pre):\n",
    "    tr=copy.deepcopy(train)\n",
    "    te=copy.deepcopy(test)\n",
    "    word_all={}\n",
    "    timing=[]\n",
    "    timing.append(time.time())\n",
    "    if pre=='tf-idf':\n",
    "        word_all=idf(tr['text'])\n",
    "    timing.append(time.time())\n",
    "    w=Online_Perceptron(tr,word_all,pre)\n",
    "    timing.append(time.time())\n",
    "    count=0\n",
    "    for i in range(len(te['text'])):\n",
    "        vec=representation(te['text'][i],word_all,pre)\n",
    "        dot=dic_dot(w,vec)\n",
    "        label=1\n",
    "        if te['label'][i]==0:\n",
    "            label=-1\n",
    "        if dot*label>0:\n",
    "            count+=1\n",
    "    timing.append(time.time())\n",
    "    accuracy=count/len(te['text'])\n",
    "    pn=posi_nega(w)\n",
    "    return {'accu':accuracy,\n",
    "            'step1':timing[1]-timing[0],\n",
    "            'step2':timing[2]-timing[1],\n",
    "            'step3':timing[3]-timing[2],\n",
    "            'posi_nega':pn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr=pandas.read_csv('reviews_tr.csv',header=0)\n",
    "data_te=pandas.read_csv('reviews_te.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr={}\n",
    "ttr['text']=copy.deepcopy(data_tr['text'][:100000])\n",
    "ttr['label']=copy.deepcopy(data_tr['label'][:100000])\n",
    "tte={}\n",
    "tte['text']=copy.deepcopy(data_te['text'][:100000])\n",
    "tte['label']=copy.deepcopy(data_te['label'][:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re100000b=testit(ttr,tte,pre='bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accu': 0.859,\n",
       "  'posi_nega': {'nega': [('ok', -79.18108189181082),\n",
       "    ('okay', -65.72382761723829),\n",
       "    ('bland', -64.70832916708329),\n",
       "    ('decent', -64.54054594540547),\n",
       "    ('worst', -50.32446755324468),\n",
       "    ('nothing', -48.358864113588645),\n",
       "    ('mediocre', -45.68173182681732),\n",
       "    ('average', -44.76842315768423),\n",
       "    ('not', -44.17398260173983),\n",
       "    ('terrible', -42.53904609539046)],\n",
       "   'posi': [('awesome', 48.49595040495951),\n",
       "    ('fresh', 49.214878512148786),\n",
       "    ('favorite', 49.98300169983002),\n",
       "    ('best', 55.36556344365564),\n",
       "    ('great', 55.81661833816619),\n",
       "    ('amazing', 63.87091290870913),\n",
       "    ('definitely', 68.33286671332867),\n",
       "    ('excellent', 73.68023197680232),\n",
       "    ('perfect', 74.79932006799321),\n",
       "    ('delicious', 95.05099490050995)]},\n",
       "  'step1': 0.0,\n",
       "  'step2': 29.63592219352722,\n",
       "  'step3': 1.514094591140747},\n",
       " {'accu': 0.88512,\n",
       "  'posi_nega': {'nega': [('mediocre', -156.12238877611225),\n",
       "    ('worst', -155.74240257597424),\n",
       "    ('bland', -140.16636833631665),\n",
       "    ('unfortunately', -124.15451845481546),\n",
       "    ('horrible', -123.63123368766313),\n",
       "    ('terrible', -115.79417205827943),\n",
       "    ('disappointment', -115.67826321736783),\n",
       "    ('disappointing', -110.92680073199269),\n",
       "    ('awful', -106.2749372506275),\n",
       "    ('ok', -105.56447435525645)],\n",
       "   'posi': [('wonderful', 86.65856341436586),\n",
       "    ('fantastic', 89.57822421775784),\n",
       "    ('excellent', 89.75641243587565),\n",
       "    ('glad', 90.92910070899292),\n",
       "    ('perfectly', 99.26302736972632),\n",
       "    ('incredible', 99.26710732892671),\n",
       "    ('amazing', 100.70463295367047),\n",
       "    ('delicious', 106.12369876301238),\n",
       "    ('perfection', 108.50911490885092),\n",
       "    ('perfect', 115.08044919550805)]},\n",
       "  'step1': 0.0,\n",
       "  'step2': 769.1888587474823,\n",
       "  'step3': 14.926757574081421},\n",
       " {'accu': 0.8375,\n",
       "  'posi_nega': {'nega': [('ok', -38.17135173014629),\n",
       "    ('not', -38.12537998863662),\n",
       "    ('bland', -30.734169108963986),\n",
       "    ('okay', -30.486393877552693),\n",
       "    ('decent', -29.6671573709152),\n",
       "    ('average', -29.665392539170945),\n",
       "    ('mediocre', -29.29108065072822),\n",
       "    ('supposed', -28.904314901405595),\n",
       "    ('worst', -26.800052200475157),\n",
       "    ('sort', -26.77547157927138)],\n",
       "   'posi': [('stromboli', 22.462738502599727),\n",
       "    ('excellent', 24.55462525480808),\n",
       "    ('perfectly', 25.494075072827997),\n",
       "    ('perfect', 26.762158908477904),\n",
       "    ('love', 29.447610000525064),\n",
       "    ('best', 34.442721886252144),\n",
       "    ('definitely', 36.09804727636711),\n",
       "    ('delicious', 37.37149188144732),\n",
       "    ('great', 37.982943400937515),\n",
       "    ('amazing', 38.624633432991274)]},\n",
       "  'step1': 136.7605049610138,\n",
       "  'step2': 23.313093900680542,\n",
       "  'step3': 1.9366605281829834},\n",
       " {'accu': 0.8374,\n",
       "  'posi_nega': {'nega': [('theworst', -23.327367263273675),\n",
       "    ('hadbetter', -16.06309369063094),\n",
       "    ('wasok', -15.426257374262574),\n",
       "    ('justok', -15.333566643335667),\n",
       "    ('iguess', -14.829117088291172),\n",
       "    ('notvery', -14.73082691730827),\n",
       "    ('dryand', -14.384561543845615),\n",
       "    ('notworth', -14.328967103289672),\n",
       "    ('tastedlike', -14.206879312068795),\n",
       "    ('overcooked', -14.123487651234877)],\n",
       "   'posi': [('yelpcom', 15.546445355464455),\n",
       "    ('wasexcellent', 15.551644835516448),\n",
       "    ('wasgreat', 16.52064793520648),\n",
       "    ('nottoo', 16.551544845515448),\n",
       "    ('5stars', 16.583141685831418),\n",
       "    ('woulddefinitely', 18.304569543045698),\n",
       "    ('thechef', 18.499150084991502),\n",
       "    ('willdefinitely', 19.265973402659736),\n",
       "    ('biz_photospjpjgxh5lgjtijos9gqetq', 20.0),\n",
       "    ('pjpjgxh5lgjtijos9gqetqselect', 20.0)]},\n",
       "  'step1': 0.0,\n",
       "  'step2': 199.59152817726135,\n",
       "  'step3': 1.957775354385376}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re10000u,re100000u,re10000idf,re10000b,re100000b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
