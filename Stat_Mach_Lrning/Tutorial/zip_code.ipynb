{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 11: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you are supposed to design a convolutional neural network for a familiar data set—the ZIP code data. We will use the images for all ten digits as the training set, and evaluate the model on a separate test set. zip.train and zip.test can be downloaded on Canvas.\n",
    "\n",
    "We recommend you to use Keras. Keras is a high-level neural networks API, written in Python. You can find the installation instructions and a brief introduction at https://keras.io. Before installing Keras, make sure that you have installed Python (https://www.python.org) on you computer (either Python 2 or 3). IPython Notebook (https://ipython.org/notebook.html) is also recommended. There are several examples of Keras with Python code provided at https://github.com/fchollet/keras/tree/master/examples.\n",
    "\n",
    "Here, we have a classification problem with ten classes. The inputs are 16 × 16 images. We will design a convolutional neural network for this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import csv\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size =32\n",
    "num_classes = 10\n",
    "epochs = 30\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 16, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.loadtxt(\"zip.train\")\n",
    "test = np.loadtxt(\"zip.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train[:, 1:].astype('float32')\n",
    "y_train = train[:, 0]\n",
    "x_test = test[:, 1:].astype('float32')\n",
    "y_test = test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7291, 16, 16, 1)\n",
      "7291 train samples\n",
      "2007 test samples\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = ( 1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = ( img_rows, img_cols, 1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linxiliu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (2, 2), padding=\"same\", input_shape=(16, 16, 1...)`\n",
      "/Users/linxiliu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (2, 2))`\n",
      "/Users/linxiliu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (2, 2), padding=\"same\")`\n",
      "/Users/linxiliu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (2, 2))`\n",
      "/Users/linxiliu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:19: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(beta_regularizer=None, epsilon=0.001, beta_initializer=\"zero\", gamma_initializer=\"ones\", weights=None, gamma_regularizer=None, momentum=0.99, axis=-1)`\n",
      "/Users/linxiliu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:21: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(beta_regularizer=None, epsilon=0.001, beta_initializer=\"zero\", gamma_initializer=\"ones\", weights=None, gamma_regularizer=None, momentum=0.99, axis=-1)`\n"
     ]
    }
   ],
   "source": [
    "# build the model sequentially\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(16, 2, 2, border_mode='same',\n",
    "                        input_shape= input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(16, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 2, 2, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(BatchNormalization(epsilon=0.001, axis=-1, momentum=0.99, weights=None, beta_init='zero', gamma_init='ones', gamma_regularizer=None, beta_regularizer=None))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization(epsilon=0.001, axis=-1, momentum=0.99, weights=None, beta_init='zero', gamma_init='ones', gamma_regularizer=None, beta_regularizer=None))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a function that adds little noise to training data\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=6,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.12,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.12,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linxiliu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=30, validation_data=(array([[[..., steps_per_epoch=227)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "227/227 [==============================] - 3s - loss: 1.3001 - acc: 0.5748 - val_loss: 2.1644 - val_acc: 0.6721\n",
      "Epoch 2/30\n",
      "227/227 [==============================] - 2s - loss: 0.5699 - acc: 0.8219 - val_loss: 0.6682 - val_acc: 0.8994\n",
      "Epoch 3/30\n",
      "227/227 [==============================] - 2s - loss: 0.3970 - acc: 0.8740 - val_loss: 0.2234 - val_acc: 0.9372\n",
      "Epoch 4/30\n",
      "227/227 [==============================] - 2s - loss: 0.3247 - acc: 0.8973 - val_loss: 0.1908 - val_acc: 0.9392\n",
      "Epoch 5/30\n",
      "227/227 [==============================] - 2s - loss: 0.2876 - acc: 0.9067 - val_loss: 0.1473 - val_acc: 0.9567\n",
      "Epoch 6/30\n",
      "227/227 [==============================] - 2s - loss: 0.2422 - acc: 0.9269 - val_loss: 0.1511 - val_acc: 0.9562\n",
      "Epoch 7/30\n",
      "227/227 [==============================] - 2s - loss: 0.2179 - acc: 0.9306 - val_loss: 0.1393 - val_acc: 0.9571\n",
      "Epoch 8/30\n",
      "227/227 [==============================] - 2s - loss: 0.2069 - acc: 0.9348 - val_loss: 0.1208 - val_acc: 0.9636\n",
      "Epoch 9/30\n",
      "227/227 [==============================] - 2s - loss: 0.1780 - acc: 0.9434 - val_loss: 0.1268 - val_acc: 0.9646\n",
      "Epoch 10/30\n",
      "227/227 [==============================] - 2s - loss: 0.1731 - acc: 0.9468 - val_loss: 0.1217 - val_acc: 0.9626\n",
      "Epoch 11/30\n",
      "227/227 [==============================] - 2s - loss: 0.1656 - acc: 0.9487 - val_loss: 0.1270 - val_acc: 0.9666\n",
      "Epoch 12/30\n",
      "227/227 [==============================] - 2s - loss: 0.1657 - acc: 0.9464 - val_loss: 0.1180 - val_acc: 0.9666\n",
      "Epoch 13/30\n",
      "227/227 [==============================] - 2s - loss: 0.1444 - acc: 0.9544 - val_loss: 0.1063 - val_acc: 0.9696\n",
      "Epoch 14/30\n",
      "227/227 [==============================] - 2s - loss: 0.1522 - acc: 0.9562 - val_loss: 0.1089 - val_acc: 0.9706\n",
      "Epoch 15/30\n",
      "227/227 [==============================] - 2s - loss: 0.1269 - acc: 0.9613 - val_loss: 0.1228 - val_acc: 0.9686\n",
      "Epoch 16/30\n",
      "227/227 [==============================] - 2s - loss: 0.1209 - acc: 0.9623 - val_loss: 0.1057 - val_acc: 0.9711\n",
      "Epoch 17/30\n",
      "227/227 [==============================] - 2s - loss: 0.1331 - acc: 0.9626 - val_loss: 0.1210 - val_acc: 0.9691\n",
      "Epoch 18/30\n",
      "227/227 [==============================] - 2s - loss: 0.1222 - acc: 0.9603 - val_loss: 0.1137 - val_acc: 0.9681\n",
      "Epoch 19/30\n",
      "227/227 [==============================] - 2s - loss: 0.1261 - acc: 0.9596 - val_loss: 0.1092 - val_acc: 0.9701\n",
      "Epoch 20/30\n",
      "227/227 [==============================] - 2s - loss: 0.1171 - acc: 0.9632 - val_loss: 0.1057 - val_acc: 0.9731\n",
      "Epoch 21/30\n",
      "227/227 [==============================] - 2s - loss: 0.1133 - acc: 0.9632 - val_loss: 0.1280 - val_acc: 0.9661\n",
      "Epoch 22/30\n",
      "227/227 [==============================] - 2s - loss: 0.1159 - acc: 0.9653 - val_loss: 0.1110 - val_acc: 0.9706\n",
      "Epoch 23/30\n",
      "227/227 [==============================] - 2s - loss: 0.1015 - acc: 0.9675 - val_loss: 0.1130 - val_acc: 0.9736\n",
      "Epoch 24/30\n",
      "227/227 [==============================] - 2s - loss: 0.1059 - acc: 0.9671 - val_loss: 0.1144 - val_acc: 0.9736\n",
      "Epoch 25/30\n",
      "227/227 [==============================] - 2s - loss: 0.0982 - acc: 0.9696 - val_loss: 0.1150 - val_acc: 0.9686\n",
      "Epoch 26/30\n",
      "227/227 [==============================] - 2s - loss: 0.1041 - acc: 0.9667 - val_loss: 0.1082 - val_acc: 0.9721\n",
      "Epoch 27/30\n",
      "227/227 [==============================] - 2s - loss: 0.1008 - acc: 0.9665 - val_loss: 0.1101 - val_acc: 0.9721\n",
      "Epoch 28/30\n",
      "227/227 [==============================] - 2s - loss: 0.0959 - acc: 0.9693 - val_loss: 0.1224 - val_acc: 0.9716\n",
      "Epoch 29/30\n",
      "227/227 [==============================] - 2s - loss: 0.0886 - acc: 0.9744 - val_loss: 0.1170 - val_acc: 0.9706\n",
      "Epoch 30/30\n",
      "227/227 [==============================] - 2s - loss: 0.0960 - acc: 0.9690 - val_loss: 0.1216 - val_acc: 0.9711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18189d9fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    samples_per_epoch=x_train.shape[0],\n",
    "                    nb_epoch = epochs,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.121616516067\n",
      "Test accuracy: 0.971101146108\n"
     ]
    }
   ],
   "source": [
    "# prediction accuracy of the fitted model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will compare this model to a linear model---a generalized linear model with $L_1$ penalty. Here is the result. First, we set the tuning parameter to be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import sklearn.linear_model as skl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train[:, 1:]\n",
    "y_train = train[:, 0].astype(np.int32)\n",
    "x_test = test[:, 1:]\n",
    "y_test = test[:, 0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy under C=1 is 0.912805181863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linxiliu/anaconda/lib/python2.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = skl.LogisticRegression(penalty=\"l1\", multi_class='multinomial', C=1, solver='saga')\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "err = np.mean(y_pred != y_test)\n",
    "print(\"The prediction accuracy under C=1 is {0}\".format(1 - err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cross validation to select the tuning parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cs = np.exp(np.linspace(-5, 8, 20))\n",
    "nfold = 5\n",
    "lrCV = skl.LogisticRegressionCV(Cs=Cs,\n",
    "                                cv=nfold, penalty=\"l1\",\n",
    "                                solver='saga',\n",
    "                                multi_class=\"multinomial\",\n",
    "                                scoring=\"neg_log_loss\",\n",
    "                                refit=True)\n",
    "lrCV.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal tuned prediction accuracy (5-fold CV) is 0.911808669656\n"
     ]
    }
   ],
   "source": [
    "y_pred_optimal = lrCV.predict(x_test)\n",
    "err_optimal = np.mean(y_pred_optimal != y_test)\n",
    "print(\"The optimal tuned prediction accuracy (5-fold CV) is {0}\".format(1 - err_optimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_avg = -np.mean(lrCV.scores_[0], axis=0)\n",
    "score_std = np.std(lrCV.scores_[0], axis=0) / np.sqrt(nfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAGJCAYAAACZ9AT5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF3QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2e3eba50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fg = plt.figure(figsize=(6, 6))\n",
    "ax = fg.add_subplot(1, 1, 1)\n",
    "ax.set_title(\"$L_1$ Penalized Logistic Regression Path\")\n",
    "ax.set_xlabel(\"$\\log(\\lambda)$\")\n",
    "ax.set_ylabel(\"CV Error\")\n",
    "ax.errorbar(-np.log(Cs), score_avg, yerr=score_std, capsize=2, marker='.', ms=10, mfc=\"red\", color=\"red\", ecolor=\"red\")\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of convolutional neural networks is better than the linear method."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
